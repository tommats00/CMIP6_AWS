{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3b2d9bf-000b-4c78-826a-43644f8f7f4b",
   "metadata": {},
   "source": [
    "# Opening and Querying the CMIP6 Catalog\n",
    "### Authors\n",
    "\n",
    "Samantha Stevenson sstevenson@ucsb.edu\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "[Goals](#purpose)\n",
    "\n",
    "[Import Packages](#path)\n",
    "\n",
    "[Load the CMIP6 AWS Catalog](#load)\n",
    "\n",
    "[Query the Database](#query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8b4f24-a58c-49e0-8697-0dd93268b21a",
   "metadata": {},
   "source": [
    "<a id='purpose'></a> \n",
    "## **Goals**\n",
    "\n",
    "In this tutorial, we will be reading in the database of Coupled Model Intercomparison Project phase 6 (CMIP6) output hosted by Amazon Web Services and exploring its contents. \n",
    "\n",
    "Our goal here isn't necessarily to plot anything - rather, we're just trying to understand what this catalog contains and how to query it for what we're looking for! If you'd like to skip directly to the plotting stage, please see [tutorial 2]() in this repo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13965a9-d341-4bc1-a0d5-ffc43c85b570",
   "metadata": {},
   "source": [
    "<a id='path'></a> \n",
    "## **Import Packages**\n",
    "\n",
    "As always, we begin by importing the necessary packages for our analysis. The packages that are new for this tutorial are:\n",
    "- `intake` \n",
    "- `intake-esm`\n",
    "- `s3fs`\n",
    "\n",
    "The idea behind `intake` is that it can be a unified interface regardless of the data source on a remote server, which provides a consistent API regardless of where the data is or what format it's stored in. It relies on \"catalogs\" of data on the remote server, which contain inventories of all the data available and the locations in which it's stored. `intake` also interfaces really well with packages like pandas and xarray - basically, it lets you synthesize a bunch of data on a server and read it in quickly as an easy-to-manipulate object within Python.\n",
    "\n",
    "In addition to `intake`, `intake-esm` is also needed to parse the CMIP6 data catalogs we're working with today. `intake-esm` is a plugin that layers on top of `intake` - so it actually requires that `intake` be installed in order to function. `intake-esm` provides additional tools to search, filter, and load netCDF information (or, as we'll see later, \"zarr\" format data) and understands the metadata structure associated with CMIP6 and many other ensembles of climate information.\n",
    "\n",
    "The final new package we'll need is `s3fs`, which provides a file system interface to the [Amazon Simple Storage Service (S3)](https://aws.amazon.com/s3/). This allows a user to read and write files directly from the S3 server, and integrates with xarray and intake. \n",
    "\n",
    "More detail on how intake, intake-esm, and s3fs work can be found at:\n",
    "- The [intake Read the Docs page](https://intake.readthedocs.io/en/latest/scope2.html)\n",
    "- The [intake-esm Read the Docs page](https://intake-esm.readthedocs.io/en/v2021.8.17/user-guide/index.html)\n",
    "- This handy [Youtube explainer](https://www.youtube.com/watch?v=QVogieGP4Jw)\n",
    "- The [s3fs Read the Docs page](https://s3fs.readthedocs.io/en/latest/)\n",
    "\n",
    "To install these packages, you can use either pip or conda, as usual.\n",
    "\n",
    "**NOTE: although we DO need to install intake-esm for this notebook to run, we do NOT need to import it as a separate package. Calling intake after installing intake-esm should result in you having all the functionality you'll need!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4df3780-3893-4811-b5eb-1e9ac562018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import intake\n",
    "import s3fs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d4a4a0-5b21-42b8-8194-cb36342a379c",
   "metadata": {},
   "source": [
    "<a id='load'></a> \n",
    "## **Load the CMIP6 AWS Catalog** \n",
    "\n",
    "The next step is to read the data we'd like for our analysis into Python. Here we will NOT be downloading any files to a local machine! Instead, we'll rely on one of the various catalogs of climate model output hosted on cloud computing servers. This one is a set of CMIP6 output maintained by Amazon Web Services. \n",
    "\n",
    "You can find more information on the data catalog here:\n",
    "\n",
    "[Blog post: CMIP6 provided through the Amazon Sustainability Data Initiative](https://aws.amazon.com/blogs/publicsector/now-available-cmip6-dataset-foster-climate-innovation-study-impact-future-climate-conditions/)\n",
    "\n",
    "[Registry of Open Data (AWS)](https://registry.opendata.aws/cmip6/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cfc3c0-547e-48a8-9f7e-c9d3b3194f48",
   "metadata": {},
   "source": [
    "### **Use intake to open data catalog**\n",
    "\n",
    "Let's first take a look at the whole data catalog to get a sense of what's in there! \n",
    "\n",
    "The `intake-esm` package contains a function called `open_esm_datastore` which can read the JSON file describing the contents of the CMIP6 data holdings. This will be parsed and can be stored as a \"catalog\" object that can be further queried within Python to grab the part of it a user is interested in.\n",
    "\n",
    "More details on `open_esm_datastore`:\n",
    "\n",
    "[Read the Docs \"Loading a Catalog\" page](https://intake-esm.readthedocs.io/en/v2021.8.17/user-guide/overview.html#loading-a-catalog)\n",
    "\n",
    "(note that the link above uses a different data catalog than the one we're working with here, but the principle is the same!)\n",
    "\n",
    "_**The CMIP6 data catalog is quite large, so this code block may take 1-2 minutes to run:**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eafab4e7-bbe3-4368-a8db-b78b50d34f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the CMIP6 data catalog, store as a variable\n",
    "catalog = intake.open_esm_datastore('https://cmip6-pds.s3.amazonaws.com/pangeo-cmip6.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6cb0e1e-d2e0-478a-a64a-5332d79441d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HighResMIP', 'CMIP', 'CFMIP', 'LUMIP', 'OMIP', 'FAFMIP', 'GMMIP',\n",
       "       'AerChemMIP', 'ScenarioMIP', 'DAMIP', 'RFMIP', 'C4MIP', 'CDRMIP',\n",
       "       'PMIP', 'LS3MIP', 'DCPP', 'PAMIP', 'ISMIP6'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the catalog to get a summary of its contents\n",
    "catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5502746d-cc60-4474-9337-29d36b7b60a9",
   "metadata": {},
   "source": [
    "As you can see from the code block above, there is an enormous amount of data in this catalog! We definitely don't want to look at the entire thing all at once.\n",
    "\n",
    "A convenient way to display subsets of the catalog entries is to convert it to a data frame using the syntax `catalog.df`. This will convert it to Pandas dataframe format, which makes it much easier to work with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c59f16bf-a3ce-4f8d-b0ca-279be92773e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       activity_id       institution_id      source_id       experiment_id  \\\n",
      "0       HighResMIP                 CMCC   CMCC-CM2-HR4  highresSST-present   \n",
      "1       HighResMIP                 CMCC   CMCC-CM2-HR4  highresSST-present   \n",
      "2       HighResMIP                 CMCC   CMCC-CM2-HR4  highresSST-present   \n",
      "3       HighResMIP                 CMCC   CMCC-CM2-HR4  highresSST-present   \n",
      "4       HighResMIP                 CMCC   CMCC-CM2-HR4  highresSST-present   \n",
      "...            ...                  ...            ...                 ...   \n",
      "522212        CMIP  EC-Earth-Consortium  EC-Earth3-Veg          historical   \n",
      "522213        CMIP  EC-Earth-Consortium  EC-Earth3-Veg          historical   \n",
      "522214        CMIP  EC-Earth-Consortium  EC-Earth3-Veg          historical   \n",
      "522215        CMIP  EC-Earth-Consortium  EC-Earth3-Veg          historical   \n",
      "522216        CMIP  EC-Earth-Consortium  EC-Earth3-Veg          historical   \n",
      "\n",
      "       member_id table_id variable_id grid_label  \\\n",
      "0       r1i1p1f1     Amon          ta         gn   \n",
      "1       r1i1p1f1     Amon        tauv         gn   \n",
      "2       r1i1p1f1     Amon          zg         gn   \n",
      "3       r1i1p1f1     Amon         vas         gn   \n",
      "4       r1i1p1f1     Amon         tas         gn   \n",
      "...          ...      ...         ...        ...   \n",
      "522212  r1i1p1f1     Amon         uas         gr   \n",
      "522213  r1i1p1f1     Amon          va         gr   \n",
      "522214  r1i1p1f1     Amon         wap         gr   \n",
      "522215  r1i1p1f1     Amon         tas         gr   \n",
      "522216  r1i1p1f1     Amon         vas         gr   \n",
      "\n",
      "                                                   zstore  dcpp_init_year  \\\n",
      "0       s3://cmip6-pds/CMIP6/HighResMIP/CMCC/CMCC-CM2-...             NaN   \n",
      "1       s3://cmip6-pds/CMIP6/HighResMIP/CMCC/CMCC-CM2-...             NaN   \n",
      "2       s3://cmip6-pds/CMIP6/HighResMIP/CMCC/CMCC-CM2-...             NaN   \n",
      "3       s3://cmip6-pds/CMIP6/HighResMIP/CMCC/CMCC-CM2-...             NaN   \n",
      "4       s3://cmip6-pds/CMIP6/HighResMIP/CMCC/CMCC-CM2-...             NaN   \n",
      "...                                                   ...             ...   \n",
      "522212  s3://cmip6-pds/CMIP6/CMIP/EC-Earth-Consortium/...             NaN   \n",
      "522213  s3://cmip6-pds/CMIP6/CMIP/EC-Earth-Consortium/...             NaN   \n",
      "522214  s3://cmip6-pds/CMIP6/CMIP/EC-Earth-Consortium/...             NaN   \n",
      "522215  s3://cmip6-pds/CMIP6/CMIP/EC-Earth-Consortium/...             NaN   \n",
      "522216  s3://cmip6-pds/CMIP6/CMIP/EC-Earth-Consortium/...             NaN   \n",
      "\n",
      "         version  \n",
      "0       20170706  \n",
      "1       20170706  \n",
      "2       20170706  \n",
      "3       20170706  \n",
      "4       20170706  \n",
      "...          ...  \n",
      "522212  20211207  \n",
      "522213  20211207  \n",
      "522214  20211207  \n",
      "522215  20211207  \n",
      "522216  20211207  \n",
      "\n",
      "[522217 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the catalog to a Pandas dataframe\n",
    "cat_df = catalog.df\n",
    "\n",
    "# print the contents of the dataframe\n",
    "print(cat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26d0443-eb59-4f67-a76d-03f81f83a1be",
   "metadata": {},
   "source": [
    "<a id='query'></a> \n",
    "## **Query the Database**\n",
    "\n",
    "In order to find specific information in the CMIP6 AWS catalog, we need to know what the appropriate search terms are. The terminology that AWS uses is slightly different from the way that things are specified on the CMIP6 website, because why make things too easy....?\n",
    "\n",
    "You can see the fields that are listed in the AWS catalog from the `print(catalog)` statement above. Here is a translation chart to explain the most important ones (the fields that you'll generally be searching over):\n",
    "\n",
    "- `activity_id`: This is the name of the \"activity\", or overall model intercomparison project (MIP), you're interested in. There are a lot of these, and you don't need to worry about most of them right now! (The idea behind the MIPs is explained in the [CMIP and other MIPs](https://climate-datalab.org/cmip-and-sub-mips/) page on the Climate DataLab website).\n",
    "\n",
    "   For most applications, the ones you'll want are `CMIP` and `ScenarioMIP`. The `CMIP` activity is where the data for the historical period (1850-2015) is located, and the `ScenarioMIP` activity contains all the future projections (2015-2100).\n",
    "  \n",
    "- `source_id`: This is the name of the actual climate model you're interested in. In our case, we want CanESM5! \n",
    "\n",
    "- `institution_id`: This is the name of the \"institution\", or modeling center, which ran a given simulation. _Don't worry too much about this one_, because you can just search by the name of the model itself and get the same result. But for reference here: the modeling center which created the CanESM5 is the Canadian Centre for Climate Modeling and Analysis. See the [Models vs Modeling Centers](https://climate-datalab.org/models-vs-modeling-centers/) explainer on the Climate DataLab site if you're curious about how this works!\n",
    "\n",
    "- `experiment_id`: This is the name of the specific type of \"experiment\" included in CMIP or ScenarioMIP. The ones you'll want here are `historical` (which is part of the CMIP \"activity\"), and one of the SSP future scenarios (which are part of ScenarioMIP). \n",
    "\n",
    "  You can pick which futures you're interested in! The main four scenarios used for CMIP6 are `ssp126`, `ssp245`, `ssp370`, and `ssp585`. Here higher numbers after `ssp` mean more overall warming (technically, the numbers are equal to the \"radiative imbalance\" at the top of the atmosphere, or difference between energy coming in and going out). \n",
    "\n",
    "- `member_id`: This is the name of the individual ensemble member run for a given \"experiment\" and \"source_id\". In our case, we're looking for a member_id of r10i1p1f1.\n",
    "\n",
    "- `table_id`: This is equivalent to the \"realm\" terminology used on the Earth System Grid; basically, which portion of the Earth do you want to be looking at? They're in different tables in the cloud database. In this case, we want the monthly averages for atmospheric variables, which is a table id of \"Amon\".\n",
    "\n",
    "- `variable_id`: This is the name of the individual variable you're interested in visualizing. In this case, we're interested in surface air temperature, or \"tas\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb404d14-9418-4e8b-b6ed-c2b8ef7433a8",
   "metadata": {},
   "source": [
    "#### Example: finding all the different activity types\n",
    "\n",
    "One thing you might want to do is to display the set of all \"activities\" - these are the various types of model experimental setups contributing to CMIP6, described in the Climate DataLab [CMIP and other MIPs page](https://climate-datalab.org/cmip-and-sub-mips/). \n",
    "\n",
    "You can accomplish this using the `.unique()` syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "635b082f-476e-43c4-8092-df25eadcef8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HighResMIP', 'CMIP', 'CFMIP', 'LUMIP', 'OMIP', 'FAFMIP', 'GMMIP',\n",
       "       'AerChemMIP', 'ScenarioMIP', 'DAMIP', 'RFMIP', 'C4MIP', 'CDRMIP',\n",
       "       'PMIP', 'LS3MIP', 'DCPP', 'PAMIP', 'ISMIP6'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display all unique CMIP6 activities\n",
    "catalog.df.activity_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e615bad-051a-4ce1-8b5c-8bfaeeeda544",
   "metadata": {},
   "source": [
    "Here, we'll be sticking with the activities\n",
    "\n",
    "- \"CMIP\": where the historical simulations are located\n",
    "- \"ScenarioMIP\": where the future projection simulations are located"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c82189-5cdf-4616-a157-9525610e2163",
   "metadata": {},
   "source": [
    "#### Example: finding all the unique model names contributing to a given activity\n",
    "\n",
    "You might also be wondering: ok, let's take one activity like CMIP. How do I see which models actually ran simulations for that one?\n",
    "\n",
    "For this, it's a good idea to first run a search through the catalog to reduce the size of the information you're working with. You can do this with the `.search()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c828532-483e-4a1e-8ea0-c38caaf9b0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search through catalog, find all historical simulations\n",
    "# (\"activity_id=CMIP\", \"experiment_id=historical\")\n",
    "res = catalog.search(activity_id=\"CMIP\", experiment_id=\"historical\")\n",
    "\n",
    "# Convert to a data frame\n",
    "res_df = res.df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5684bdae-6006-4edd-b57d-f7f41787e7a0",
   "metadata": {},
   "source": [
    "From there, you can find the unique set of models in the data frame by applying the `.unique()` function to the `source_id` field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61699d0d-6a13-4aa5-8395-98bacfc8f4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GFDL-CM4' 'GFDL-ESM4' 'IPSL-CM6A-LR' 'GISS-E2-1-G' 'CNRM-CM6-1'\n",
      " 'BCC-CSM2-MR' 'BCC-ESM1' 'CNRM-ESM2-1' 'MIROC6' 'AWI-CM-1-1-MR'\n",
      " 'MRI-ESM2-0' 'CESM2-WACCM' 'CanESM5' 'CESM2' 'SAM0-UNICON' 'GISS-E2-1-H'\n",
      " 'UKESM1-0-LL' 'EC-Earth3' 'CanESM5-CanOE' 'INM-CM4-8' 'EC-Earth3-Veg'\n",
      " 'INM-CM5-0' 'HadGEM3-GC31-LL' 'MPI-ESM-1-2-HAM' 'NESM3' 'CAMS-CSM1-0'\n",
      " 'MPI-ESM1-2-LR' 'MPI-ESM1-2-HR' 'E3SM-1-0' 'MCM-UA-1-0' 'NorESM2-LM'\n",
      " 'GISS-E2-1-G-CC' 'FGOALS-g3' 'FGOALS-f3-L' 'MIROC-ES2L' 'KACE-1-0-G'\n",
      " 'NorCPM1' 'CNRM-CM6-1-HR' 'KIOST-ESM' 'NorESM2-MM' 'ACCESS-CM2'\n",
      " 'FIO-ESM-2-0' 'ACCESS-ESM1-5' 'CESM2-FV2' 'CESM2-WACCM-FV2' 'GISS-E2-2-H'\n",
      " 'E3SM-1-1' 'HadGEM3-GC31-MM' 'IITM-ESM' 'CIESM' 'E3SM-1-1-ECA'\n",
      " 'AWI-ESM-1-1-LR' 'EC-Earth3-Veg-LR' 'TaiESM1' 'CAS-ESM2-0' 'CMCC-CM2-SR5'\n",
      " 'EC-Earth3-AerChem' 'IPSL-CM5A2-INCA' 'CMCC-CM2-HR4' 'EC-Earth3P-VHR'\n",
      " 'EC-Earth3-CC' 'CMCC-ESM2' 'MIROC-ES2H' 'ICON-ESM-LR' 'IPSL-CM6A-LR-INCA']\n"
     ]
    }
   ],
   "source": [
    "# Get unique model names in the set of search results\n",
    "models = res_df.source_id.unique()\n",
    "\n",
    "# Print list of model names\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a687737a-9f25-4743-ba01-4bba44ebd1de",
   "metadata": {},
   "source": [
    "#### Example: finding all the historical simulations with a given model\n",
    "\n",
    "You might also want to see how many simulations of a certain type there are. Let's try a more specific example: figuring out how many historical simulations were run with the model called \"CanESM5\". \n",
    "\n",
    "This would start the same way as the example above - by searching through the catalog to find all the historical simulations. But now we'll add another search term, on the `source_id` field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f81317c2-1119-43ac-996c-3dd3886c6fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search through catalog, find all historical simulations with CanESM5\n",
    "# (\"activity_id=CMIP\", \"experiment_id=historical\", \"source_id=CanESM5\")\n",
    "res = catalog.search(activity_id=\"CMIP\", experiment_id=\"historical\", source_id=\"CanESM5\")\n",
    "\n",
    "# Convert to a data frame\n",
    "res_df = res.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b037560-495d-4ae5-9166-bcde496f48fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['r24i1p1f1' 'r25i1p1f1' 'r14i1p1f1' 'r2i1p1f1' 'r17i1p1f1' 'r10i1p1f1'\n",
      " 'r13i1p1f1' 'r7i1p1f1' 'r6i1p1f1' 'r5i1p1f1' 'r3i1p1f1' 'r22i1p1f1'\n",
      " 'r23i1p1f1' 'r8i1p1f1' 'r11i1p1f1' 'r12i1p1f1' 'r15i1p1f1' 'r19i1p1f1'\n",
      " 'r16i1p1f1' 'r1i1p1f1' 'r9i1p1f1' 'r18i1p1f1' 'r4i1p1f1' 'r21i1p1f1'\n",
      " 'r20i1p1f1' 'r11i1p2f1' 'r10i1p2f1' 'r7i1p2f1' 'r9i1p2f1' 'r8i1p2f1'\n",
      " 'r4i1p2f1' 'r40i1p2f1' 'r3i1p2f1' 'r6i1p2f1' 'r24i1p2f1' 'r13i1p2f1'\n",
      " 'r12i1p2f1' 'r5i1p2f1' 'r31i1p2f1' 'r30i1p2f1' 'r32i1p2f1' 'r29i1p2f1'\n",
      " 'r28i1p2f1' 'r2i1p2f1' 'r22i1p2f1' 'r23i1p2f1' 'r26i1p2f1' 'r27i1p2f1'\n",
      " 'r25i1p2f1' 'r37i1p2f1' 'r38i1p2f1' 'r39i1p2f1' 'r35i1p2f1' 'r34i1p2f1'\n",
      " 'r36i1p2f1' 'r33i1p2f1' 'r1i1p2f1' 'r18i1p2f1' 'r19i1p2f1' 'r14i1p2f1'\n",
      " 'r15i1p2f1' 'r17i1p2f1' 'r16i1p2f1' 'r21i1p2f1' 'r20i1p2f1']\n"
     ]
    }
   ],
   "source": [
    "# Print all unique ensemble members (\"member_id\")\n",
    "members = res_df.member_id.unique()\n",
    "\n",
    "print(members)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e654edc-7467-4a8c-ba08-a0ebca69dc35",
   "metadata": {},
   "source": [
    "### **Find a specific file**\n",
    "\n",
    "Let's do an example of pulling the data we used in previous tutorials, this time from the cloud. The example data file from the [Time Series Plots](https://github.com/climate-datalab/Time-Series-Plots) and [Map Plots](https://github.com/climate-datalab/Map-Plots) repositories is:\n",
    "\n",
    "`tas_Amon_CanESM5_historical_r10i1p1f1_gn_185001-201412.nc`\n",
    "\n",
    "We can break this down to extract the fields we'll need to search the data catalog properly. If you need more detail on how to do this, also refer to the [filename decoder](http://climate-datalab.org/filename-decoder/) on the Climate DataLab website!\n",
    "\n",
    "#### **Characteristics of this file (corresponding fields in the CMIP6 catalog are in parentheses)**:\n",
    "- _Variable (\"variable_id\")_: This is a surface air temperature, or \"tas\", variable.\n",
    "- _Realm (\"table_id\")_: Surface air temperature is generated by the atmosphere component of a climate model (\"A\"), and the information in this particular file is averaged monthly (\"mon\").\n",
    "- _Model (\"source_id\")_: The name of the model is \"CanESM5\", which is short for the Canadian Earth System Model version 5.\n",
    "- _Experiment (\"experiment_id\")_: The name of the model experiment being run. The file above is a _historical_ simulation: since we're also interested in the future projection information, we'll further specify that we'd also like the associated SSPs below.\n",
    "- _Ensemble member (\"member_id\")_: The name of this ensemble member is \"r10i1p1f1\".\n",
    "- _Grid_: This output is provided on the model's _native grid_ (\"gn\"), instead of doing any kind of interpolating to a different grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7329ec43-8cd9-4e4f-8a85-54a42a3c83c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify search terms to query catalog for CanESM5 data\n",
    "# activity_id: which project do you want? CMIP = historical data, ScenarioMIP = future projections\n",
    "activity_ids = ['ScenarioMIP', 'CMIP'] \n",
    "\n",
    "# source_id: which model do you want? \n",
    "source_id = ['CanESM5']\n",
    "\n",
    "# experiment_id: what experimental configuration do you want? Here we want historical and the four main SSPs\n",
    "experiment_ids = ['historical', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
    "\n",
    "# member_id: which ensemble member do you want? Here we want r10i1p1f1\n",
    "member_id = 'r10i1p1f1'\n",
    "\n",
    "# table_id: which part of the Earth system and time resolution do you want? Here we want monthly atmosphere data\n",
    "table_id = 'Amon' \n",
    "\n",
    "# variable_id: which climate variable do you want? Here we want surface air temperature\n",
    "variable_id = 'tas' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2658080e-5e4b-49bf-9d40-ad0ca8ada62d",
   "metadata": {},
   "source": [
    "#### **Display catalog search results**\n",
    "\n",
    "The code block above specifies the search terms to use to get the `r10i1p1f1` member of the CanESM5 historical and SSP ensembles. To actually retrieve the information, we use the `.search` functionality that `catalog` type objects possess. \n",
    "\n",
    "The code block below parses through the full CMIP6 catalog and retrieves only entries that satisfy our search criteria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b64d7ea4-e581-46dd-8dc4-0eccc3e6109c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_id</th>\n",
       "      <th>institution_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>table_id</th>\n",
       "      <th>variable_id</th>\n",
       "      <th>grid_label</th>\n",
       "      <th>zstore</th>\n",
       "      <th>dcpp_init_year</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CMIP</td>\n",
       "      <td>CCCma</td>\n",
       "      <td>CanESM5</td>\n",
       "      <td>historical</td>\n",
       "      <td>r10i1p1f1</td>\n",
       "      <td>Amon</td>\n",
       "      <td>tas</td>\n",
       "      <td>gn</td>\n",
       "      <td>s3://cmip6-pds/CMIP6/CMIP/CCCma/CanESM5/histor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20190429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ScenarioMIP</td>\n",
       "      <td>CCCma</td>\n",
       "      <td>CanESM5</td>\n",
       "      <td>ssp585</td>\n",
       "      <td>r10i1p1f1</td>\n",
       "      <td>Amon</td>\n",
       "      <td>tas</td>\n",
       "      <td>gn</td>\n",
       "      <td>s3://cmip6-pds/CMIP6/ScenarioMIP/CCCma/CanESM5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20190429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ScenarioMIP</td>\n",
       "      <td>CCCma</td>\n",
       "      <td>CanESM5</td>\n",
       "      <td>ssp370</td>\n",
       "      <td>r10i1p1f1</td>\n",
       "      <td>Amon</td>\n",
       "      <td>tas</td>\n",
       "      <td>gn</td>\n",
       "      <td>s3://cmip6-pds/CMIP6/ScenarioMIP/CCCma/CanESM5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20190429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ScenarioMIP</td>\n",
       "      <td>CCCma</td>\n",
       "      <td>CanESM5</td>\n",
       "      <td>ssp126</td>\n",
       "      <td>r10i1p1f1</td>\n",
       "      <td>Amon</td>\n",
       "      <td>tas</td>\n",
       "      <td>gn</td>\n",
       "      <td>s3://cmip6-pds/CMIP6/ScenarioMIP/CCCma/CanESM5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20190429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ScenarioMIP</td>\n",
       "      <td>CCCma</td>\n",
       "      <td>CanESM5</td>\n",
       "      <td>ssp245</td>\n",
       "      <td>r10i1p1f1</td>\n",
       "      <td>Amon</td>\n",
       "      <td>tas</td>\n",
       "      <td>gn</td>\n",
       "      <td>s3://cmip6-pds/CMIP6/ScenarioMIP/CCCma/CanESM5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20190429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activity_id institution_id source_id experiment_id  member_id table_id  \\\n",
       "0         CMIP          CCCma   CanESM5    historical  r10i1p1f1     Amon   \n",
       "1  ScenarioMIP          CCCma   CanESM5        ssp585  r10i1p1f1     Amon   \n",
       "2  ScenarioMIP          CCCma   CanESM5        ssp370  r10i1p1f1     Amon   \n",
       "3  ScenarioMIP          CCCma   CanESM5        ssp126  r10i1p1f1     Amon   \n",
       "4  ScenarioMIP          CCCma   CanESM5        ssp245  r10i1p1f1     Amon   \n",
       "\n",
       "  variable_id grid_label                                             zstore  \\\n",
       "0         tas         gn  s3://cmip6-pds/CMIP6/CMIP/CCCma/CanESM5/histor...   \n",
       "1         tas         gn  s3://cmip6-pds/CMIP6/ScenarioMIP/CCCma/CanESM5...   \n",
       "2         tas         gn  s3://cmip6-pds/CMIP6/ScenarioMIP/CCCma/CanESM5...   \n",
       "3         tas         gn  s3://cmip6-pds/CMIP6/ScenarioMIP/CCCma/CanESM5...   \n",
       "4         tas         gn  s3://cmip6-pds/CMIP6/ScenarioMIP/CCCma/CanESM5...   \n",
       "\n",
       "   dcpp_init_year   version  \n",
       "0             NaN  20190429  \n",
       "1             NaN  20190429  \n",
       "2             NaN  20190429  \n",
       "3             NaN  20190429  \n",
       "4             NaN  20190429  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Search through catalog, store results in \"res\" variable\n",
    "res = catalog.search(activity_id=activity_ids, source_id=source_id, experiment_id=experiment_ids, \n",
    "                     member_id=member_id, table_id=table_id, variable_id=variable_id)\n",
    "\n",
    "# Display data frame associated with results\n",
    "display(res.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29741927-fedb-4850-b352-6d0bf8454129",
   "metadata": {},
   "source": [
    "Now we're in business! The search above returned five results:\n",
    "\n",
    "- one historical simulation (\"experiment_id\" = \"historical\")\n",
    "- four future projection simulations (\"experiment_id\" = \"ssp585\", \"ssp370\", \"ssp126\", or \"ssp245\")\n",
    "\n",
    "We can now follow a procedure similar to the one we used in previous tutorials, to read in the data as xarray objects and make our time series and map plots. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdad6134-5daf-4151-af5f-c2846115f14f",
   "metadata": {},
   "source": [
    "### **Read information and store as an xarray object**\n",
    "\n",
    "Let's first read in the data for just the historical simulation. To do this, we'll use the following command:\n",
    "\n",
    "`xr.open_zarr(res.df['zstore'][0], storage_options={'anon': True}) `\n",
    "\n",
    "This is part of the `xarray` package, and is designed to allow us to read in information stored as _zarr stores_. \n",
    "\n",
    "_**What's a zarr store??**_\n",
    "\n",
    "`zarr`, like netCDF, is a self-describing data storage format, meaning that all the metadata and coordinate information you need to understand the data is packaged up with the data itself. However, it's been optimized for accessibility via cloud/parallelized servers, which is why many of the cloud-based data catalogs contain data stored in zarr format. _**Essentially, zarr is the cloud-optimized version of a netCDF file!**_\n",
    "\n",
    "The historical data file is the first one returned in our catalog search above. So we want to retrieve the first value in the `zstore` column of the `res` dataframe, which will tell Python how to retrieve the relevant information. \n",
    "\n",
    "The final thing we need to pass to `open_zarr` is a flag that tells it to ignore any login information - since this is a publicly available database, we don't need it. That's what the `storage_options={'anon': True}` argument is doing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d1b9ca6-5489-4069-bb3e-4292a6cd63db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samstevenson/opt/anaconda3/lib/python3.8/site-packages/fsspec/registry.py:279: UserWarning: Your installed version of s3fs is very old and known to cause\n",
      "severe performance issues, see also https://github.com/dask/dask/issues/10276\n",
      "\n",
      "To fix, you should specify a lower version bound on s3fs, or\n",
      "update the current installation.\n",
      "\n",
      "  warnings.warn(s3_msg)\n"
     ]
    }
   ],
   "source": [
    "# Read in just the historical data file\n",
    "hist_data = xr.open_zarr(res.df['zstore'][0], storage_options={'anon': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedf685e-9c14-4b15-961d-53207a13cd9d",
   "metadata": {},
   "source": [
    "We can print out the data to see what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e58a0999-7595-4bf2-854f-65a5d75bb58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:    (lat: 64, bnds: 2, lon: 128, time: 1980)\n",
      "Coordinates:\n",
      "    height     float64 ...\n",
      "  * lat        (lat) float64 -87.86 -85.1 -82.31 -79.53 ... 82.31 85.1 87.86\n",
      "    lat_bnds   (lat, bnds) float64 dask.array<chunksize=(64, 2), meta=np.ndarray>\n",
      "  * lon        (lon) float64 0.0 2.812 5.625 8.438 ... 348.8 351.6 354.4 357.2\n",
      "    lon_bnds   (lon, bnds) float64 dask.array<chunksize=(128, 2), meta=np.ndarray>\n",
      "  * time       (time) object 1850-01-16 12:00:00 ... 2014-12-16 12:00:00\n",
      "    time_bnds  (time, bnds) object dask.array<chunksize=(1980, 2), meta=np.ndarray>\n",
      "Dimensions without coordinates: bnds\n",
      "Data variables:\n",
      "    tas        (time, lat, lon) float32 dask.array<chunksize=(600, 64, 128), meta=np.ndarray>\n",
      "Attributes: (12/56)\n",
      "    CCCma_model_hash:            55f484f90aff0e32c5a8e92a42c6b9ae7ffe6224\n",
      "    CCCma_parent_runid:          rc3.1-pictrl\n",
      "    CCCma_pycmor_hash:           33c30511acc319a98240633965a04ca99c26427e\n",
      "    CCCma_runid:                 rc3.1-his10\n",
      "    Conventions:                 CF-1.7 CMIP-6.2\n",
      "    YMDH_branch_time_in_child:   1850:01:01:00\n",
      "    ...                          ...\n",
      "    variable_id:                 tas\n",
      "    variant_label:               r10i1p1f1\n",
      "    version:                     v20190429\n",
      "    status:                      2019-10-25;created;by nhn2@columbia.edu\n",
      "    netcdf_tracking_ids:         hdl:21.14100/5ed65f32-a352-4bd1-83a4-c659b4f...\n",
      "    version_id:                  v20190429\n"
     ]
    }
   ],
   "source": [
    "print(hist_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85265440-d10a-4627-9dc0-0ed7bc575686",
   "metadata": {},
   "source": [
    "Sure enough, this results in an xarray Dataset that looks essentially identical to the one we got when we downloaded the CanESM5 historical data manually! (compare with the results of the tutorials in the Time Series Plots repo for yourself if you like)\n",
    "\n",
    "Some of the dimensions might be listed in a different order, but that doesn't matter to xarray since it knows how to find them based on their names... now that you've read in the data, you can do anything with it that you would with any other xarray dataset!\n",
    "\n",
    "Now let's read in a second data file, one that goes with one of the SSP future projection simulations: say, SSP3-7.0. Looking at the data table above, we see that this is the third entry - so we grab the location of the third file and feed it to `xr.open_zarr` as we did for the historical simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbfcbeab-7b22-41bc-ac7e-85779450e9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data for SSP370\n",
    "ssp370_data = xr.open_zarr(res.df['zstore'][2], storage_options={'anon': True})\n",
    "\n",
    "# Print the contents\n",
    "print(ssp370_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2159a18-f5e3-4a6a-b41d-78ac011f745a",
   "metadata": {},
   "source": [
    "Great job! Now it should be more clear that you can use **EITHER** the manual download **OR** the cloud computing solution to access the same datasets, and do all the same analysis tasks. The ability to quickly pull data down from the cloud makes it much easier to carry out complicated analyses, so it's a great skill to have!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a99cf6d-09d7-4bb6-9383-16221d1c4439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
